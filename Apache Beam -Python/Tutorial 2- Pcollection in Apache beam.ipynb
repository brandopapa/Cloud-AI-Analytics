{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pcollection_Apachebeam.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **PCollection Introduction in Apache Beam:**"
      ],
      "metadata": {
        "id": "Y8mjhyiJvcNx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **PCollection:**\n",
        "\n",
        "#### A PCollection is a data set or data stream. The data that a pipeline processes is part of a PCollection.\n",
        "\n",
        "It is an abstraction represents a potentially distributed, multi-element data set. It represents a distributed data set that our beam pipeline operates on.\n",
        "\n",
        "o\t**Immutability:** Pcollections are immutable in nature. Applying a transformations on a pcollection results in creation of new pcollection.\n",
        "\n",
        "o\t**Element type:** The elements in pcollection may be of any type, but all must be of same type.\n",
        "\n",
        "o **Element Schema:** Element type in a **PCollection** has a structure that can introspected. Examples are JSON, Protocol Buffer, Avro, and database records. Schemas provide a way to express types as a set of named fields, allowing for more-expressive aggregations.\n",
        "\n",
        "o\t**Operation type:**  Pcollection does not support grained operations. We cannot apply transformations on specific elements in pcollection.\n",
        "\n",
        "o\t**Timestamps:** Each element in pcollection has an associated timestamp with it.\n",
        "\n",
        "o **Creating a Pcollection:** create a PCollection by either reading data from an external source using Beam’s Source API (or) can create a PCollection of data stored in an in-memory collection class in your driver program.\n",
        "\n",
        "o\t**Unbounded pcollections:** An unbounded PCollection represents a data set of unlimited size. Example: Streaming data from pubsub. Source assigns the timestamps.\n",
        "\n",
        "o\t**Bounded pcollections:** A bounded PCollection represents a data set of a known fixed size. Example: Batch data. Every element is set to same timestamp.\n",
        "\n",
        "o\t**No Random access:** Can’t access data using index or some specific element. No size restriction.\n",
        "\n",
        "o\t**Ptransform:** Ptransform represent a data processing operation, or a step in our pipeline. Ex., Map, Groupby, FlatMap, ParDo, filter, flatten, combine etc.\n",
        "\n",
        "•\t**PCollection characteristics:**\n",
        "o\tA PCollection is owned by the specific Pipeline object for which it is created; multiple pipelines cannot share a PCollection.\n",
        "\n",
        "### •\t***Resources:***\n",
        "\n",
        "o\thttps://beam.apache.org/documentation/programming-guide/#pcollections\n",
        "\n",
        "o\thttps://beam.apache.org/releases/pydoc/2.36.0/apache_beam.io.textio.html?highlight=readfromtext#apache_beam.io.textio.ReadFromText\n"
      ],
      "metadata": {
        "id": "RQgMvERwwx8Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gwZRMnrri8xv"
      },
      "outputs": [],
      "source": [
        "#installation of apache beam   https://github.com/vigneshSs-07/Cloud-AI-Analytics/tree/main/Apache%20Beam%20-Python\n",
        "!pip3 install apache_beam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing library\n",
        "import apache_beam as beam"
      ],
      "metadata": {
        "id": "mO9xkORejAKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "jAkFyZm7XjdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd drive/My\\ Drive/Colab\\ Notebooks/Cloud-AI-Analytics/Apache\\ Beam\\ -Python/data"
      ],
      "metadata": {
        "id": "3iLSDE0VXykc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "mabdNgVsX0n5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat cloud_export_100.txt"
      ],
      "metadata": {
        "id": "PXrHxuKBX2VL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from external resources\n",
        "p1 = beam.Pipeline()\n",
        "\n",
        "cloud_cdr = (p1\n",
        "           | \"Read from Text\" >> beam.io.ReadFromText(\"cloud_export_100.txt\", skip_header_lines=1)\n",
        "           | \"split the record\" >> beam.Map(lambda record: record.split(','))\n",
        "           | 'Filter compute engine' >> beam.Filter(lambda record: record[2] == 'Compute Engine')\n",
        "           | 'Write to text'>> beam.io.WriteToText('result/compute_engine_filter'))\n",
        "#| beam.Map(print))\n",
        "\n",
        "p1.run()"
      ],
      "metadata": {
        "id": "45sVHxWFjBBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./result"
      ],
      "metadata": {
        "id": "zkPneCrLjBF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat result/compute_engine_filter-00000-of-00001"
      ],
      "metadata": {
        "id": "fDEjCpnEjBJM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#In memory\n",
        "with beam.Pipeline() as pipeline:\n",
        "  lines = (\n",
        "      pipeline\n",
        "      | beam.Create([\n",
        "          'To be, or not to be: that is the question: ',\n",
        "          \"Whether 'tis nobler in the mind to suffer \",\n",
        "          'The slings and arrows of outrageous fortune, ',\n",
        "          'Or to take arms against a sea of troubles, ',\n",
        "      ]))"
      ],
      "metadata": {
        "id": "TmDwo6EgjBT9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lines"
      ],
      "metadata": {
        "id": "NjKYimc8vQR-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}