{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tutorial 3h - Side Inputs and Outputs Apache Beam.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MbnvkOmI1XgG",
        "outputId": "4888a7f5-374b-4386-e88f-854c30dd50ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apache_beam\n",
            "  Downloading apache_beam-2.60.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Collecting crcmod<2.0,>=1.7 (from apache_beam)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: orjson<4,>=3.9.7 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (3.10.10)\n",
            "Collecting dill<0.3.2,>=0.3.1.1 (from apache_beam)\n",
            "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/152.0 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting cloudpickle~=2.2.1 (from apache_beam)\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting fastavro<2,>=0.23.6 (from apache_beam)\n",
            "  Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\n",
            "Collecting fasteners<1.0,>=0.3 (from apache_beam)\n",
            "  Downloading fasteners-0.19-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: grpcio!=1.48.0,!=1.59.*,!=1.60.*,!=1.61.*,!=1.62.0,!=1.62.1,<1.66.0,<2,>=1.33.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.64.1)\n",
            "Collecting hdfs<3.0.0,>=2.1.0 (from apache_beam)\n",
            "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: httplib2<0.23.0,>=0.8 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (0.22.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (4.23.0)\n",
            "Requirement already satisfied: jsonpickle<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (3.3.0)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.14.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.26.4)\n",
            "Collecting objsize<0.8.0,>=0.6.1 (from apache_beam)\n",
            "  Downloading objsize-0.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: packaging>=22.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (24.1)\n",
            "Collecting pymongo<5.0.0,>=3.8.0 (from apache_beam)\n",
            "  Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Requirement already satisfied: proto-plus<2,>=1.7.1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (1.25.0)\n",
            "Requirement already satisfied: protobuf!=4.0.*,!=4.21.*,!=4.22.0,!=4.23.*,!=4.24.*,<4.26.0,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (3.20.3)\n",
            "Collecting pydot<2,>=1.2.0 (from apache_beam)\n",
            "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2024.2)\n",
            "Collecting redis<6,>=5.0.0 (from apache_beam)\n",
            "  Downloading redis-5.2.0-py3-none-any.whl.metadata (9.1 kB)\n",
            "Requirement already satisfied: regex>=2020.6.8 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2024.9.11)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (4.12.2)\n",
            "Collecting zstandard<1,>=0.18.0 (from apache_beam)\n",
            "  Downloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pyarrow<17.0.0,>=3.0.0 (from apache_beam)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pyarrow-hotfix<1 in /usr/local/lib/python3.10/dist-packages (from apache_beam) (0.6)\n",
            "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache_beam)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from hdfs<3.0.0,>=2.1.0->apache_beam) (1.16.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<0.23.0,>=0.8->apache_beam) (3.2.0)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache_beam) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache_beam) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache_beam) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema<5.0.0,>=4.0.0->apache_beam) (0.20.0)\n",
            "Collecting dnspython<3.0.0,>=1.16.0 (from pymongo<5.0.0,>=3.8.0->apache_beam)\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: async-timeout>=4.0.3 in /usr/local/lib/python3.10/dist-packages (from redis<6,>=5.0.0->apache_beam) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.24.0->apache_beam) (2024.8.30)\n",
            "Downloading apache_beam-2.60.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Downloading fastavro-1.9.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fasteners-0.19-py3-none-any.whl (18 kB)\n",
            "Downloading objsize-0.7.0-py3-none-any.whl (11 kB)\n",
            "Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
            "Downloading pymongo-4.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m41.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading redis-5.2.0-py3-none-any.whl (261 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading zstandard-0.23.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: crcmod, dill, hdfs, docopt\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31406 sha256=0006200dfdde0cabe73fd6968f74c6489a9bf89243e5a5853a631467d2e9d921\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78542 sha256=9f7322569b06fffea5fd075b7bc506b8effc070d8611c1d150ef5f82f3867fb3\n",
            "  Stored in directory: /root/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
            "  Building wheel for hdfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34324 sha256=7a7814349c91e1e1cc8ef8e3507d5d78ea7f5c6229cc7a8f42a33413aebd2871\n",
            "  Stored in directory: /root/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=17d7943701240a7d7ef62e555186555d4c95ca2e767af3eaf4863217d02a43e3\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "Successfully built crcmod dill hdfs docopt\n",
            "Installing collected packages: docopt, crcmod, zstandard, redis, pydot, pyarrow, objsize, fasteners, fastavro, dnspython, dill, cloudpickle, pymongo, hdfs, apache_beam\n",
            "  Attempting uninstall: pydot\n",
            "    Found existing installation: pydot 3.0.2\n",
            "    Uninstalling pydot-3.0.2:\n",
            "      Successfully uninstalled pydot-3.0.2\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 17.0.0\n",
            "    Uninstalling pyarrow-17.0.0:\n",
            "      Successfully uninstalled pyarrow-17.0.0\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.0\n",
            "    Uninstalling cloudpickle-3.1.0:\n",
            "      Successfully uninstalled cloudpickle-3.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dask 2024.10.0 requires cloudpickle>=3.0.0, but you have cloudpickle 2.2.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed apache_beam-2.60.0 cloudpickle-2.2.1 crcmod-1.7 dill-0.3.1.1 dnspython-2.7.0 docopt-0.6.2 fastavro-1.9.7 fasteners-0.19 hdfs-2.7.3 objsize-0.7.0 pyarrow-16.1.0 pydot-1.4.2 pymongo-4.10.1 redis-5.2.0 zstandard-0.23.0\n"
          ]
        }
      ],
      "source": [
        "!pip install apache_beam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import apache_beam as beam"
      ],
      "metadata": {
        "id": "b_nHkDVY1YM8"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "pxxH31LRCb3M",
        "outputId": "5812e353-2cb8-4af2-e51a-1ca5370b4144",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Colab Notebooks/Cloud-AI-Analytics/Apache\\ Beam\\ -Python/data"
      ],
      "metadata": {
        "id": "7-ruh3z0CeoE",
        "outputId": "de26d8e2-b835-49c4-8dbf-d98056a7e799",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Colab Notebooks/Cloud-AI-Analytics/Apache Beam -Python/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "AgBxSfPrDdyZ",
        "outputId": "086e1034-baac-4704-eace-3718f71e4d87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "data\t       grocery.txt\t\t\t  result\t    students_exclude.txt\n",
            "dept_data.txt  regular_filter.txt-00000-of-00001  Students_age.txt  students.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{('head -n 10 students_exclude.txt')}"
      ],
      "metadata": {
        "id": "EVtDoRUKDkXE",
        "outputId": "8d2c4eca-89a3-4c89-a609-84076793f651",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\r\n",
            "3\r\n",
            "7\r\n",
            "9"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Side Inputs**:\n",
        "\n",
        "•\tA side input is an additional input that your DoFn can access each time it processes an element in the input PCollection.\n",
        "\n",
        "•\tIn addition to the main input PCollection, you can provide additional inputs to a ParDo transform in the form of side inputs.\n"
      ],
      "metadata": {
        "id": "izqHdabn2b05"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = beam.Pipeline()\n",
        "\n",
        "input_list = list()\n",
        "with open ('students_exclude.txt','r') as exclude_file:\n",
        "  for stud_id in exclude_file:\n",
        "    input_list.append(stud_id.rstrip())\n",
        "\n",
        "print(input_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7NxsA4Sz1YRX",
        "outputId": "3320f455-0229-485b-ede0-158e7b386f9e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', '3', '7', '9']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SplitRow(beam.DoFn):\n",
        "  def process(self,element,input_list):\n",
        "    customer = element.split(',')\n",
        "    if customer[0] not in input_list:\n",
        "      return [customer]\n",
        "\n",
        "customers = (\n",
        "    p1\n",
        "    |beam.io.ReadFromText('Students_age.txt')\n",
        "    |beam.ParDo(SplitRow(),input_list)  #can pass any number of side inputs in this ParDo function\n",
        "    |beam.io.WriteToText('data/output')\n",
        ")\n",
        "p1.run()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "fqqxEOGV1YV0",
        "outputId": "bd05ea11-4adb-40c5-f8a3-e8e7399fbde4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
              "          var jqueryScript = document.createElement('script');\n",
              "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
              "          jqueryScript.type = 'text/javascript';\n",
              "          jqueryScript.onload = function() {\n",
              "            var datatableScript = document.createElement('script');\n",
              "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
              "            datatableScript.type = 'text/javascript';\n",
              "            datatableScript.onload = function() {\n",
              "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
              "              window.interactive_beam_jquery(document).ready(function($){\n",
              "                \n",
              "              });\n",
              "            }\n",
              "            document.head.appendChild(datatableScript);\n",
              "          };\n",
              "          document.head.appendChild(jqueryScript);\n",
              "        } else {\n",
              "          window.interactive_beam_jquery(document).ready(function($){\n",
              "            \n",
              "          });\n",
              "        }"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7ff20a042980>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{('head -n 10 data/output-00000-of-00001')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_88PAwd2M_D",
        "outputId": "ae79d33e-64d2-483d-f6a8-b1a6ef70dc5d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2', 'farooqui', 'hyd', '26']\n",
            "['4', 'neethu', 'mla', '27', '']\n",
            "['5', 'joey', 'ny', '57']\n",
            "['6', 'ross', 'la', '60']\n",
            "['8', 'lois', 'us', '50']\n",
            "['10', 'sai', 'chn', '29']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Side Outputs/Additional Outputs:**\n",
        "\n",
        "\n",
        "\n",
        "*   Additional outputs in parDo transformation\n",
        "\n",
        "*   While ParDo always produces a main output PCollection (as the return value from apply), you can also have your ParDo produce any number of additional output PCollections.\n",
        "\n"
      ],
      "metadata": {
        "id": "AjuXDDBI3Qax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "p1 = beam.Pipeline()\n",
        "\n",
        "side_list = list()\n",
        "with open ('students_exclude.txt','r') as exclude_file:\n",
        "  for cust_id in exclude_file:\n",
        "    side_list.append(cust_id.rstrip())\n",
        "\n",
        "print(side_list)\n",
        "\n",
        "class SplitRow(beam.DoFn):\n",
        "  def process(self,element,side_list):\n",
        "    customer = element.split(',')\n",
        "    if customer[0] not in side_list:\n",
        "      return [customer]\n",
        "\n",
        "class ProcessCustomers(beam.DoFn):\n",
        "  def process(self,element,country,start_char):\n",
        "    if(element[2]==country):\n",
        "      yield  element\n",
        "    else:\n",
        "      yield  beam.pvalue.TaggedOutput('Other_student',element)\n",
        "    if(element[1].startswith('r')):\n",
        "       yield  beam.pvalue.TaggedOutput('Names_r',element)\n",
        "\n",
        "\n",
        "\n",
        "customers = (\n",
        "    p1\n",
        "    |beam.io.ReadFromText('Students_age.txt')\n",
        "    |beam.ParDo(SplitRow(),side_list)\n",
        "    |beam.ParDo(ProcessCustomers(),'chn','r').with_outputs('Names_r','Other_student',main='Chennai_Cust')\n",
        ")\n",
        "\n",
        "chennai_customers = customers.Chennai_Cust\n",
        "other_cities_customers = customers.Other_student\n",
        "customer_withname_r = customers.Names_r\n",
        "\n",
        "chennai_customers | 'Write Chennai Students PCollection' >> beam.io.WriteToText(\"data/chennai\")\n",
        "other_cities_customers  | 'Write Students PCollection that lives in other cities' >> beam.io.WriteToText(\"data/students_other_cities\")\n",
        "customer_withname_r  | 'Write Students names with r PCollection' >> beam.io.WriteToText(\"data/customers_names_r\")\n",
        "\n",
        "\n",
        "p1.run()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTlEnQWd2M7g",
        "outputId": "62e46840-7c92-4214-ce80-ec0312781e18"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1', '3', '7', '9']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<apache_beam.runners.portability.fn_api_runner.fn_runner.RunnerResult at 0x7ff2095ca1a0>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cat data/chennai-00000-of-00001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4_mTC1f2M46",
        "outputId": "29060573-baf5-4ff1-e2fa-9cca0b723d58"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['10', 'sai', 'chn', '29']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat data/students_other_cities-00000-of-00001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwPyBcyP2M2M",
        "outputId": "28c3e2e1-4c71-4e89-b13e-854d408c1f20"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['2', 'farooqui', 'hyd', '26']\n",
            "['4', 'neethu', 'mla', '27', '']\n",
            "['5', 'joey', 'ny', '57']\n",
            "['6', 'ross', 'la', '60']\n",
            "['8', 'lois', 'us', '50']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat data/customers_names_r-00000-of-00001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MsKAAZ94tUh",
        "outputId": "6a6d789a-155c-47e1-f757-4c3554f6439c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['6', 'ross', 'la', '60']\n"
          ]
        }
      ]
    }
  ]
}